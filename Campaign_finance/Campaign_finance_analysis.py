
#  Campaign Finance Geography #

#from testing_tools import ...
import pandas as pd
import numpy as np
import sqlite3
from scipy.sparse import coo_matrix
import importlib
import run_tests
import pickle
import time
import geopandas as gpd


# We have ingested a sample of the raw data into a SQLite database `data.db`. The first table we will be working with is named `indiv_contrib`. Each row represents a single individual campaign contribution. It has 5 columns.
#
# 0. index - autogenerated index (synthetic key). - INTEGER
# 1. CMTE_ID - committee id receiving a contribution. - TEXT
# 2. TRANSACTION_TP - transaction type code. - TEXT
# 3. ZIP_CODE - ZIP code from which a contribution was made. - TEXT
# 4. TRANSACTION_AMT - Dollar amount of a contribution. -INTEGER
# 5. MEMO_CD - extra data about the transaction - Will always be `NULL` due to our preprocessing.

# Demo cell - run this cell before moving on.
conn = sqlite3.connect('resource/asnlib/publicdata/data.db')
pd.read_sql_query('''
    SELECT *
    FROM indiv_contrib
    ORDER BY random() limit 10
''', conn)


# Write a SQL query to return the **ZIP code**, **committee id**, and **total amount donated** to the committee from the ZIP code. The column names in your result should be `zip`, `cmte`, and `total`. Your results should be sorted by ZIP code with ties broken by committee id.
#
# Store the query as a string in a variable named `query`.

query = '''
            SELECT ZIP_CODE AS zip, CMTE_ID AS cmte, SUM(TRANSACTION_AMT) AS total
            FROM indiv_contrib
            GROUP BY zip, cmte
            ORDER BY zip, cmte;
           '''
# The demo cell below should produce the following output.
#
# ```
#               zip       cmte  total
# 245424  481898262  C00694323     13
# 123189  234511007  C00694323     75
# 70102   128351844  C00694323     23
# 139260  286127773  C00694323     75
# 219586  413110947  C00694323    100
# 206873  370874263  C00694323     50
# 89596   191037507  C00669358    500
# 250160      48823  C00618371    292
# 64827   117472016  C00042366     25
# 69251   125534796  C00118943     37
# ```

# In[4]:


# Demo cell - run this cell before moving on.
grouped_contrib = pd.read_sql_query(query, conn)
print(grouped_contrib.sample(10, random_state=6040))

# loads variables from latest test cell run for debugging
from ex0 import test_input, test_output, your_output

query_1 = '''
            SELECT SUBSTR(c.ZIP_CODE,1,5) AS zip, d.CAND_NAME AS  candidate, SUM(c.TRANSACTION_AMT) AS total
            FROM grouped_contrib AS c
            JOIN candidate AS d ON c.CMTE_ID = d.CAND_PCC
            GROUP BY zip, candidate
            ORDER BY zip, candidate'''


# Demo cell - run this cell before moving on.
df = pd.read_sql_query(query_1, conn)
print(df.sample(10, random_state=6040))
if False:
    with open('resource/asnlib/publicdata/df.pkl', 'wb') as f:
        pickle.dump(df, f)

def filter_zip(df, zips):
    return df[df['zip'].isin(zips)].copy()


# loads variables from latest test cell run for debugging
from ex2 import test_df, test_zips, test_output, your_output


# Next, you need to map unique zip codes and unique candidates to integers. We'll use this result later when we convert the data into a sparse matrix.

def calc_col_map(df, col):
    a = df[col].sort_values().unique()
    return {v:i for i,v in enumerate(a)}


# loads variables from latest test cell run for debugging
from ex3 import test_df, test_col, test_output, your_output


# Suppose you are given a dataframe `df` and a column name, `col`. Suppose `df[col]` holds grouping labels and `df['total']` holds values. For instance:
#
def normalize_df(df, col):
    denom_df = df[[col, 'total']].groupby(col, as_index=False).apply(lambda x: np.linalg.norm(x['total']))
    denom_df.columns = [col,'total']
    merged = df.merge(denom_df, how='left', on=col)
    merged['total'] = merged['total_x']/merged['total_y']
    merged['total'] = merged['total'].fillna(0.0)
    return merged.drop(columns = ['total_x', 'total_y'])


norm_zip_df = normalize_df(df_filter.sample(10000, random_state=6040), 'zip')
norm_cand_df = normalize_df(df_filter.sample(10000, random_state=6040), 'candidate')
if False:
    import pickle
    with open('resource/asnlib/publicdata/norm_zip_df.pkl', 'wb') as f:
        pickle.dump(norm_zip_df, f)
    with open('resource/asnlib/publicdata/norm_cand_df.pkl', 'wb') as f:
        pickle.dump(norm_cand_df, f)
print(norm_zip_df.sort_values(by=['zip', 'candidate']).sample(10, random_state=6040))
print()
print(norm_cand_df.sort_values(by=['zip', 'candidate']).sample(10, random_state=6040))

# loads variables from latest test cell run for debugging
from ex4 import test_df, test_col, test_output, your_output

# Now that we have our maps, we can convert our dataframes to coordinate (COO) sparse matrices.

def df_to_coo(df, map_row, map_col):
    rows = df.iloc[:,0].map(map_row)
    cols = df.iloc[:,1].map(map_col)
    return coo_matrix((df.iloc[:,2].astype(float),(rows,cols)),shape=(len(map_row),len(map_col)))


def calc_similarity(mat, row_map, target):
    reverse_map = {v:k for k,v in row_map.items()}
    ind = row_map[target]
    my_dot = mat.getrow(ind).dot(mat.transpose()).toarray()[0]
#     print(my_dot)
    lot = ((reverse_map[i],val) for i,val in enumerate(my_dot))
    return pd.DataFrame(lot, columns=['key','similarity']).sort_values(['similarity'],ascending=False)

cand_sim_df = calc_similarity(cand_coo, cand_map,'TRUMP, DONALD J.')
cand_sim_df

cand_coo.getrow(1).dot(cand_coo.transpose()).toarray()[0]


# In[64]:


# Test Cell
importlib.reload(run_tests)
from run_tests import ex_6_check
ex_6_check(calc_similarity)


pd.read_sql('select * from candidate limit 1', conn)


def candidate_merge(sim_df, conn):
    md_df = pd.read_sql_query('''
    select
        CAND_NAME as candidate,
        CAND_PTY_AFFILIATION as party,
        CAND_OFFICE as office,
        CAND_OFFICE_ST as state,
        CAND_OFFICE_DISTRICT as district
    from candidate;
    ''', conn)
    return md_df.merge(sim_df, left_on='candidate', right_on='key')        .drop(columns='key')        .sort_values(['similarity'], ascending=False).reset_index(drop=True)

with open('resource/asnlib/publicdata/cand_sim_df.pkl', 'rb') as f:
    cand_sim_df = pickle.load(f)
print(candidate_merge(cand_sim_df, conn).head(10))

def zips_in_state(state, states_gdf, zipcode_gdf, sim_df):
    state_bounds = states_gdf[states_gdf['STUSPS'] == state]['geometry'].bounds.values[0]
    def compare_bounds(g):
        return g.bounds[0] > state_bounds[0] and             g.bounds[1] > state_bounds[1] and             g.bounds[2] < state_bounds[2] and             g.bounds[3] < state_bounds[3]
    in_state = zipcode_gdf['geometry'].apply(compare_bounds)
    return zipcode_gdf[in_state].merge(sim_df, left_on='GEOID10', right_on='key').drop(columns='key')


with open('resource/asnlib/publicdata/zip_sim_df.pkl', 'rb') as f:
    zip_sim_df = pickle.load(f)
